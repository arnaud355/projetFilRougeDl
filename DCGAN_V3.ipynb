{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DatasetCartoon', 'Datasetheroicfantasy', 'DatasetsagaIntergalactique', 'Datasetsuperheroes', 'DatasetVideoGamingCharacters']\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(os.listdir(\"../datasets/datasetsAugmented/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "url = \"C:/Users/arnaud.baleh/Desktop/dataIA/projetFilRouge/E1_projetFilRougeDl/datasets/VideoGamingCharacters/\"\n",
    "for path in os.listdir(url):        \n",
    "    img = load_img('C:/Users/arnaud.baleh/Desktop/dataIA/projetFilRouge/E1_projetFilRougeDl/datasets/VideoGamingCharacters/' + path)  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "    # the .flow() command below generates batches of randomly transformed images\n",
    "    # and saves the results to the `preview/` directory\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                              save_to_dir='datasets/datasetsAugmented/DatasetVideoGamingCharacters', save_prefix='VideoGamingCharacters', save_format='png'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_characters = []\n",
    "train_path_characters = \"C:/Users/arnaud.baleh/Desktop/dataIA/projetFilRouge/E1_projetFilRougeDl/datasets/datasetsAugmented/DatasetCartoon/\"\n",
    "for path in os.listdir(train_path_characters):\n",
    "    if '.png' in path:\n",
    "        path_characters.append(os.path.join(train_path_characters, path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lenghtSplit = round(len(path_characters) * 0.95)\n",
    "new_path=path_characters[0:lenghtSplit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [np.array(Image.open(path).resize((32,32))) for path in path_characters]\n",
    "\n",
    "for i in range(len(images)):\n",
    "    images[i] = ((images[i] - images[i].min())/(255 - images[i].min()))\n",
    "    #images[i] = images[i]*2-1  #decommenter si fonction d activation est tanh pour la dernière couche du generateur\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "train_data=images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9129, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9129, 32, 32, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9129\n"
     ]
    }
   ],
   "source": [
    "tailleInitiale = len(images)\n",
    "print(tailleInitiale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "# load numpy array from csv file\n",
    "from numpy import loadtxt\n",
    "#Pour sauvegarder un fichier numpy dans un csv file, il faut le redimensionner en 1D\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagesReshape1D = images.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28044288,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.shape(imagesReshape1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "#savetxt('csvFiles/dataCartoon.csv', imagesReshape1D, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96774194 1.         0.97177419 ... 0.9254902  0.67058824 0.56470588]\n"
     ]
    }
   ],
   "source": [
    "# load array\n",
    "#data = loadtxt('csvFiles/dataCartoon.csv', delimiter=',')\n",
    "# print the array\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagesReshape4D = data.reshape(tailleInitiale,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9129, 32, 32, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.shape(imagesReshape4D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 1/285, d1=0.671, d2=0.695 g=0.692\n",
      ">1, 2/285, d1=0.471, d2=0.697 g=0.690\n",
      ">1, 3/285, d1=0.313, d2=0.705 g=0.682\n",
      ">1, 4/285, d1=0.166, d2=0.724 g=0.665\n",
      ">1, 5/285, d1=0.077, d2=0.764 g=0.631\n",
      ">1, 6/285, d1=0.039, d2=0.827 g=0.586\n",
      ">1, 7/285, d1=0.031, d2=0.937 g=0.547\n",
      ">1, 8/285, d1=0.051, d2=1.015 g=0.540\n",
      ">1, 9/285, d1=0.107, d2=1.047 g=0.546\n",
      ">1, 10/285, d1=0.200, d2=1.056 g=0.571\n",
      ">1, 11/285, d1=0.291, d2=1.014 g=0.611\n",
      ">1, 12/285, d1=0.382, d2=0.900 g=0.670\n",
      ">1, 13/285, d1=0.459, d2=0.846 g=0.691\n",
      ">1, 14/285, d1=0.486, d2=0.820 g=0.710\n",
      ">1, 15/285, d1=0.501, d2=0.789 g=0.730\n",
      ">1, 16/285, d1=0.511, d2=0.756 g=0.775\n",
      ">1, 17/285, d1=0.549, d2=0.788 g=0.754\n",
      ">1, 18/285, d1=0.529, d2=0.762 g=0.750\n",
      ">1, 19/285, d1=0.571, d2=0.767 g=0.765\n",
      ">1, 20/285, d1=0.595, d2=0.785 g=0.755\n",
      ">1, 21/285, d1=0.581, d2=0.753 g=0.751\n",
      ">1, 22/285, d1=0.635, d2=0.745 g=0.736\n",
      ">1, 23/285, d1=0.660, d2=0.791 g=0.702\n",
      ">1, 24/285, d1=0.657, d2=0.752 g=0.710\n",
      ">1, 25/285, d1=0.677, d2=0.755 g=0.723\n",
      ">1, 26/285, d1=0.699, d2=0.755 g=0.716\n",
      ">1, 27/285, d1=0.680, d2=0.745 g=0.706\n",
      ">1, 28/285, d1=0.689, d2=0.731 g=0.705\n",
      ">1, 29/285, d1=0.700, d2=0.740 g=0.712\n",
      ">1, 30/285, d1=0.701, d2=0.731 g=0.701\n",
      ">1, 31/285, d1=0.696, d2=0.718 g=0.697\n",
      ">1, 32/285, d1=0.691, d2=0.717 g=0.703\n",
      ">1, 33/285, d1=0.703, d2=0.744 g=0.699\n",
      ">1, 34/285, d1=0.676, d2=0.725 g=0.706\n",
      ">1, 35/285, d1=0.692, d2=0.731 g=0.704\n",
      ">1, 36/285, d1=0.689, d2=0.730 g=0.695\n",
      ">1, 37/285, d1=0.675, d2=0.722 g=0.697\n",
      ">1, 38/285, d1=0.687, d2=0.721 g=0.703\n",
      ">1, 39/285, d1=0.694, d2=0.711 g=0.692\n",
      ">1, 40/285, d1=0.694, d2=0.729 g=0.697\n",
      ">1, 41/285, d1=0.689, d2=0.708 g=0.695\n",
      ">1, 42/285, d1=0.675, d2=0.717 g=0.698\n",
      ">1, 43/285, d1=0.696, d2=0.734 g=0.699\n",
      ">1, 44/285, d1=0.694, d2=0.715 g=0.693\n",
      ">1, 45/285, d1=0.696, d2=0.703 g=0.680\n",
      ">1, 46/285, d1=0.698, d2=0.728 g=0.684\n",
      ">1, 47/285, d1=0.691, d2=0.724 g=0.689\n",
      ">1, 48/285, d1=0.688, d2=0.713 g=0.688\n",
      ">1, 49/285, d1=0.695, d2=0.714 g=0.694\n",
      ">1, 50/285, d1=0.684, d2=0.724 g=0.697\n",
      ">1, 51/285, d1=0.684, d2=0.711 g=0.692\n",
      ">1, 52/285, d1=0.693, d2=0.715 g=0.688\n",
      ">1, 53/285, d1=0.692, d2=0.718 g=0.701\n"
     ]
    }
   ],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self,L,l,C):\n",
    "        self.__L = L\n",
    "        self.__l = l\n",
    "        self.__C = C\n",
    "        self.__in_shape = (self.__L,self.__l,self.__C)\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # normal\n",
    "        model.add(Conv2D(64, (3,3), padding='same', input_shape=self.__in_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # reduction echantillon\n",
    "        model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # reduction echantillon\n",
    "        model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # reduction echantillon\n",
    "        model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # classification\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # compiler modele\n",
    "        opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "class Generator:\n",
    "    def __init__(self,latent_dim):\n",
    "        self.__latent_dim = latent_dim\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # 4x4 image\n",
    "        n_nodes = 256 * 4 * 4\n",
    "        model.add(Dense(n_nodes, input_dim=self.__latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Reshape((4, 4, 256)))\n",
    "        # agrandissement echantillon à 8x8\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # agrandissement echantillon à 16*16\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # agrandissement echantillon à 32x32\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # couche de sortie\n",
    "        model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
    "        return model\n",
    " \n",
    "    # defini une combinaison du generateur et discriminateur, pour mettre à jour le generateur\n",
    "def define_gan(g_model, d_model):\n",
    "    # rendre les poids du discriminateur non entrainable\n",
    "    d_model.trainable = False\n",
    "    # les connecter\n",
    "    model = Sequential()\n",
    "    # ajout generateur\n",
    "    model.add(g_model)\n",
    "    # ajout discriminator\n",
    "    model.add(d_model)\n",
    "    # compiler le modele\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    " \n",
    "\n",
    "def load_real_samples():\n",
    "    \n",
    "    # load cifar10 dataset\n",
    "    #(trainX, _), (_, _) = load_data()\n",
    "    trainX = train_data\n",
    "  \n",
    "    # convertir d unsigned ints vers float32\n",
    "    X = trainX.astype('float32')\n",
    "    # changer l echelle de valeur [0,255] vers [-1,1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X\n",
    " \n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = g_model.predict(x_input)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "# create and save a plot of generated images\n",
    "def save_plot(examples, epoch, n=7):\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    examples = (examples + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i])\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()\n",
    " \n",
    "    # evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n",
    "    # prepare real samples\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    # save plot\n",
    "    save_plot(x_fake, epoch)\n",
    "    # save the generator model tile file\n",
    "    filename = 'generator_model_%03d.h5' % (epoch+1)\n",
    "    g_model.save(filename)\n",
    " \n",
    "    # train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=32):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(bat_per_epo):\n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            # summarize loss on this batch\n",
    "            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
    "                (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "        # evaluate the model performance, sometimes\n",
    "        if (i+1) % 10 == 0:\n",
    "            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    " \n",
    "    # size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "d_model = Discriminator(32,32,3)\n",
    "d_model = d_model.build_model()\n",
    "# create the generator\n",
    "g_model = Generator(latent_dim)\n",
    "g_model = g_model.build_model()\n",
    "# create the gan\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# exemple de generation d'une image pour un point specific dans l'espace latent\n",
    "from keras.models import load_model\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "# chargement modele\n",
    "model = load_model('generator_model_200.h5')\n",
    "# all 0s\n",
    "vector = asarray([[0.75 for _ in range(100)]])\n",
    "# generation de l'image\n",
    "X = model.predict(vector)\n",
    "# mise à l'échelle [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "# affichage du resultat\n",
    "pyplot.imshow(X[0, :, :])\n",
    "pyplot.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar",
   "language": "python",
   "name": "cifar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
